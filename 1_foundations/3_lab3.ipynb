{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF2 PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv # type: ignore\n",
    "from openai import OpenAI # type: ignore\n",
    "from pypdf import PdfReader # type: ignore\n",
    "import gradio as gr # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/Profile.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "Tejasjayprakash@gmail.com\n",
      "www.linkedin.com/in/tejas-\n",
      "jay-23809a15b (LinkedIn)\n",
      "Top Skills\n",
      "Machine Learning\n",
      "MySQL\n",
      "Python (Programming Language)\n",
      "Languages\n",
      "Telugu (Native or Bilingual)\n",
      "Tamil (Native or Bilingual)\n",
      "Kannada (Native or Bilingual)\n",
      "Hindi (Limited Working)\n",
      "English  (Professional Working)\n",
      "Certifications\n",
      "Introduction to TensorFlow\n",
      "Google Cloud Big Data and Machine\n",
      "Learning Fundamentals\n",
      "Feature Engineering\n",
      "How Google Does Machine Learning\n",
      "Perform Foundational Data, ML, and\n",
      "AI Tasks in Google Cloud\n",
      "Tejas Jay\n",
      "Analytics Engineer at Cogeco | Ex - Amazon\n",
      "Canada\n",
      "Summary\n",
      "Data-driven problem solver with a strong background in\n",
      "implementing and delivering data driven solutions and over six years\n",
      "of experience working with various technology stack. My journey\n",
      "in the world of data began as a Risk Analyst at Amazon, where I\n",
      "handled vast datasets and derived actionable insights, sparking my\n",
      "passion for data-driven decision-making.\n",
      "At PwC, I delved into the fascinating realm of Artificial Intelligence,\n",
      "successfully resolving issues related to financial crime and\n",
      "transaction data analysis. My dedication to continuous learning led\n",
      "me to pursue a postgraduate diploma in Data Analytics for Business\n",
      "at St Clair College, Ontario.\n",
      "During my academic pursuits, I engaged in enriching internships,\n",
      "such as at iNeuron.ai, where I collaborated on innovative solutions\n",
      "using AI and SSD algorithms to prevent hazardous accidents in real-\n",
      "time.\n",
      "As an Analytics Engineer at Essex Powerline Corporation, I\n",
      "developed a project optimization tool employing principles of Efficient\n",
      "Frontier and Hierarchical Risk Parity. These accomplishments paved\n",
      "the way for my current role as an Analytics Engineer at Cogeco,\n",
      "where I excel in automating tools and processes, reducing costs, and\n",
      "enhancing performance appraisals.\n",
      "Experience\n",
      "Cogeco Inc.\n",
      "Analytics Engineer - Automation tools and processes\n",
      "June 2022 - Present (3 years)\n",
      "Ontario, Canada\n",
      "Essex Powerlines Corporation\n",
      "  Page 1 of 2   \n",
      "AI Analytics Engineer\n",
      "January 2022 - May 2022 (5 months)\n",
      "Ontario, Canada\n",
      "iNeuron.ai\n",
      "Data Science Intern\n",
      "March 2021 - January 2022 (11 months)\n",
      "Toronto, Ontario, Canada\n",
      "PwC\n",
      "Data Analyst\n",
      "June 2020 - February 2021 (9 months)\n",
      "India\n",
      "MACRO TECHNOLOGIES\n",
      "Data processing analyst\n",
      "January 2019 - August 2020 (1 year 8 months)\n",
      "India\n",
      "Amazon\n",
      "Risk Analyst\n",
      "March 2017 - December 2018 (1 year 10 months)\n",
      "Bengaluru, Karnataka, India\n",
      "Education\n",
      "St. Clair College\n",
      "Postgraduate Degree, Data science for business · (2020 - 2021)\n",
      "SVCE,  Bangalore\n",
      "Bachelor's degree, Engineering · (2012 - 2016)\n",
      "  Page 2 of 2\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Tejas Jay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Tejas Jay. You are answering questions on Tejas Jay's website, particularly questions related to Tejas Jay's career, background, skills and experience. Your responsibility is to represent Tejas Jay for interactions on the website as faithfully as possible. You are given a summary of Tejas Jay's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nMy name is Tejas Jay. I'm an Analyst, software engineer and data scientist. I'm originally from India, but I moved to Canada in 2021.\\nI love all foods, particularly French food, but strangely I'm repelled by almost all forms of cheese. I'm not allergic, I just hate the taste! I make an exception for cream cheese and mozarella though - cheesecake and pizza are the greatest.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\nTejasjayprakash@gmail.com\\nwww.linkedin.com/in/tejas-\\njay-23809a15b (LinkedIn)\\nTop Skills\\nMachine Learning\\nMySQL\\nPython (Programming Language)\\nLanguages\\nTelugu (Native or Bilingual)\\nTamil (Native or Bilingual)\\nKannada (Native or Bilingual)\\nHindi (Limited Working)\\nEnglish  (Professional Working)\\nCertifications\\nIntroduction to TensorFlow\\nGoogle Cloud Big Data and Machine\\nLearning Fundamentals\\nFeature Engineering\\nHow Google Does Machine Learning\\nPerform Foundational Data, ML, and\\nAI Tasks in Google Cloud\\nTejas Jay\\nAnalytics Engineer at Cogeco | Ex - Amazon\\nCanada\\nSummary\\nData-driven problem solver with a strong background in\\nimplementing and delivering data driven solutions and over six years\\nof experience working with various technology stack. My journey\\nin the world of data began as a Risk Analyst at Amazon, where I\\nhandled vast datasets and derived actionable insights, sparking my\\npassion for data-driven decision-making.\\nAt PwC, I delved into the fascinating realm of Artificial Intelligence,\\nsuccessfully resolving issues related to financial crime and\\ntransaction data analysis. My dedication to continuous learning led\\nme to pursue a postgraduate diploma in Data Analytics for Business\\nat St Clair College, Ontario.\\nDuring my academic pursuits, I engaged in enriching internships,\\nsuch as at iNeuron.ai, where I collaborated on innovative solutions\\nusing AI and SSD algorithms to prevent hazardous accidents in real-\\ntime.\\nAs an Analytics Engineer at Essex Powerline Corporation, I\\ndeveloped a project optimization tool employing principles of Efficient\\nFrontier and Hierarchical Risk Parity. These accomplishments paved\\nthe way for my current role as an Analytics Engineer at Cogeco,\\nwhere I excel in automating tools and processes, reducing costs, and\\nenhancing performance appraisals.\\nExperience\\nCogeco Inc.\\nAnalytics Engineer - Automation tools and processes\\nJune 2022\\xa0-\\xa0Present\\xa0(3 years)\\nOntario, Canada\\nEssex Powerlines Corporation\\n\\xa0 Page 1 of 2\\xa0 \\xa0\\nAI Analytics Engineer\\nJanuary 2022\\xa0-\\xa0May 2022\\xa0(5 months)\\nOntario, Canada\\niNeuron.ai\\nData Science Intern\\nMarch 2021\\xa0-\\xa0January 2022\\xa0(11 months)\\nToronto, Ontario, Canada\\nPwC\\nData Analyst\\nJune 2020\\xa0-\\xa0February 2021\\xa0(9 months)\\nIndia\\nMACRO TECHNOLOGIES\\nData processing analyst\\nJanuary 2019\\xa0-\\xa0August 2020\\xa0(1 year 8 months)\\nIndia\\nAmazon\\nRisk Analyst\\nMarch 2017\\xa0-\\xa0December 2018\\xa0(1 year 10 months)\\nBengaluru, Karnataka, India\\nEducation\\nSt. Clair College\\nPostgraduate Degree,\\xa0Data science for business\\xa0·\\xa0(2020\\xa0-\\xa02021)\\nSVCE,  Bangalore\\nBachelor's degree,\\xa0Engineering\\xa0·\\xa0(2012\\xa0-\\xa02016)\\n\\xa0 Page 2 of 2\\n\\nWith this context, please chat with the user, always staying in character as Tejas Jay.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += f\"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I currently do not hold a patent. My focus has primarily been on data analysis, software engineering, and machine learning throughout my career. I'm always open to innovative ideas and projects, so that may change in the future as I continue to grow in my field! If you have any specific questions or opportunities in mind, feel free to share!\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"This is a great answer. It's honest and direct, but also leaves the door open to the future. It also invites the user to share any ideas they might have.\")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + f\"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed evaluation - retrying\n",
      "The agent's response is unacceptable. The agent doesn't provide a valid answer and speaks gibberish. \n",
      "Passed evaluation - returning reply\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
